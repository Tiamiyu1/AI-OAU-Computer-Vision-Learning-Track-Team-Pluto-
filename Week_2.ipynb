{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Week 2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tiamiyu1/AI-OAU-Computer-Vision-Learning-Track-Team-Pluto-/blob/main/Week_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Lj3ixOva2Ey"
      },
      "source": [
        "# Optimizer, losses and activation functions in fully connected neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt_mEyVHa2E5"
      },
      "source": [
        "## Activation function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ddjqAGfa2E6"
      },
      "source": [
        "Activation functions are computational functions for neuron computation and interaction. They are functions that engages each neuron cell in active learning of patterns between input data and its corresponding target data. To mention a few, we have sigmoid, rectified linear units (relu), exponential linear unit (elu), tanh etc. We will be looking into relu, sigmoid. In most classification problem we do have sigmoid been used as the activation function for output layers. Due to its ability to intuitively differentiate patterns learnt between two classes. Relu, has been proven mathematically as one of the activation function best suitable for hidden layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x90Eg1pSa2E7"
      },
      "source": [
        "## Loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD5L4DhMa2E7"
      },
      "source": [
        "Loss functions are mathematical algorithms that helps measure how close a neural net learns to getting the actual result. In machine learning, a loss function is a mathematical algorithm that evaluates the performance of an ML algorithm with respect to its desired result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSFRDyJGa2E7"
      },
      "source": [
        "To mention a few, we do have the following loss functions as classification based (binary cross entropy, categorical cross entropy, cosine similarity and others). We also have, mean squared error (MSE), mean absolute percentage error (MAPE), mean absolute error (MAE), just to mention a few, used for regression based problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYVUNb4Ga2E8"
      },
      "source": [
        "## An optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od_jh0E3a2E8"
      },
      "source": [
        "In simple sentences, an optimizer can basically be referred to as an algorithm that helps another algorithm to reach its peak performance without delay. With respect to machine learning (neural network), we can say an optimizer is a mathematical algorithm that helps our loss function reach its convergence point with minimum delay (and most importantly, reduce the posibility of gradient explosion). Examples include, adam, stochastic gradient descent (SGD), adadelta, rmsprop, adamax, adagrad, nadam etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZqBHmkRa2E8"
      },
      "source": [
        "## How to make your choice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TuQs0uNa2E9"
      },
      "source": [
        "When ever you are working with fully connected neural network for a classification problem do ensure you use sigmoid as the activation function for your output. If regression, you shouldn’t use any activation function for your output. You can make relu the activation function for your hidden layers. If still working on classification and you are trying to predict multi-class data, do use categorical cross entropy, else use binary cross entropy (for binary prediction). If regression, you can use mean squared error, it works like magic. For optimizers, there are no actual one way to this, but best optimizers for classification is adam and rmsprop. Gradient descent works like magic for regression problems. You need to take note that, this ain’t fixed way for all problems, they do vary in operation. So one of the best you would want to look into is model parameter hyper tuning of your neural network for optimal selection of model parameters that works best for your problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-wGZmmia2E9"
      },
      "source": [
        "References: https://medium.com/@elishatofunmi/optimizer-losses-and-activation-functions-in-fully-connected-neural-networks-e1958bc66121"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9uV7qsxa2E9"
      },
      "source": [
        "# House pricing regression with low level Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XQ3CfJGa2E-"
      },
      "source": [
        "##  Using the california housing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra0RoNyya2E_",
        "outputId": "44444b1e-a9e6-4b64-ea45-c75afac5635f"
      },
      "source": [
        "# load the dataset\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "m,n = housing.data.shape"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "90_sPNoza2FK"
      },
      "source": [
        "# pass in into a Dataframe\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(housing.data)\n",
        "target = pd.DataFrame(housing.target)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syPJ26zGa2FK"
      },
      "source": [
        "# Split into training and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.2, random_state=42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-tmoH5fa2FK"
      },
      "source": [
        "# ML Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeL79EYBa2FK",
        "outputId": "aa19413b-2fb6-41a8-c2f4-3e76c501a05a"
      },
      "source": [
        "# Trying Gradient Boost and check the performance before feeding into Neural Network model\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "# We are using GradientBoostingRegressor because it is a regression task\n",
        "# Instantiate the model, then fit to the training set\n",
        "gb = GradientBoostingRegressor()\n",
        "gb.fit(X_train, y_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
              "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
              "                          max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                          n_iter_no_change=None, presort='deprecated',\n",
              "                          random_state=None, subsample=1.0, tol=0.0001,\n",
              "                          validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpwOctr0a2FM"
      },
      "source": [
        "# Predict X_test and save it as predictions\n",
        "predictions = gb.predict(X_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QwBChM6a2FN",
        "outputId": "1e5b38cc-8627-4c5b-c31f-c40617bdc52d"
      },
      "source": [
        "# Check model performance\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print('Training score:', gb.score(X_train, y_train))\n",
        "print('Test score:', mean_squared_error(y_test, predictions) )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training score: 0.8048978817773167\n",
            "Test score: 0.2940161448268125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll8jX8XLa2FO"
      },
      "source": [
        "# Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5pYBaCHa2FO"
      },
      "source": [
        "import tensorflow.compat.v1 as tf1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a13B-d4a2FO"
      },
      "source": [
        "tf1.disable_eager_execution()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKclXryba2FO"
      },
      "source": [
        "# Define the placeholders for x and y\n",
        "\n",
        "X = tf1.placeholder(tf1.float32, shape=(None, 8), name='x')\n",
        "y = tf1.placeholder(tf1.float32, shape=(None, 1), name='y')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiflbvhVa2FP"
      },
      "source": [
        "with tf1.name_scope('loss'):\n",
        "    #theta = tf1.Variable(tf.random_uniform((8,1), -1.0, 1.0), name = 'theta')\n",
        "    import numpy as np\n",
        "    stddev = 2/np.sqrt(8)\n",
        "    w = tf1.Variable(tf1.random_normal((8,1), stddev = stddev, name = 'weights'))\n",
        "    b = tf1.Variable(tf1.zeros(m,1), name = 'biases')\n",
        "    y_pred = tf1.add(tf1.matmul(X,w),b, name= 'predictions')\n",
        "    error = y_pred - y\n",
        "    mse = tf1.reduce_mean(tf1.square(error), name = 'mse')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixyGq2Zka2FP",
        "outputId": "a57902c6-f4cb-4682-8eee-ddd11cc59eba"
      },
      "source": [
        "with tf1.name_scope('training'):\n",
        "    learning_rate = 0.01\n",
        "    optimizer= tf1.train.RMSPropOptimizer(learning_rate = learning_rate)\n",
        "    training_op = optimizer.minimize(mse)\n",
        "    init = tf1.global_variables_initializer()\n",
        "    saver = tf1.train.Saver()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/rmsprop.py:123: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho3vVAlGa2FQ"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJnDAJEfa2FQ",
        "outputId": "63d3574a-60ec-485d-9421-18e655645150"
      },
      "source": [
        "batch_size = 1000\n",
        "n_batches = int(np.ceil(16512/batch_size))\n",
        "print('number of batches is: ', str(n_batches))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of batches is:  17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP4OADXAa2FR"
      },
      "source": [
        "def fetch_batch(batch_index):\n",
        "    if batch_index < n_batches-1:\n",
        "        start = batch_index * batch_size\n",
        "        stop = batch_size + start\n",
        "        x_batch = X_train[start:stop]\n",
        "        y_batch = y_train[start:stop]\n",
        "        \n",
        "    else:\n",
        "        start = batch_index* batch_size\n",
        "        x_batch = X_train[start:]\n",
        "        y_batch = y_train[start:]\n",
        "    return x_batch, y_batch"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hj7-7Wxopey",
        "outputId": "0d8ec0a1-9589-4081-ade7-8a1c45b2db92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16512, 8), (16512, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7KASltKoxHk"
      },
      "source": [
        "m, n = X_train.shape"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yurvUmoa2FR",
        "outputId": "85b7fb51-3d28-48c0-d74d-d9bd7d3b5a56"
      },
      "source": [
        "#X = tf.constant(housing_data_plus_bias, dtype =tf.float32, name = 'X')\n",
        "#y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name = 'y')\n",
        "\n",
        "X = tf1.placeholder(tf1.float32, shape = (None,8), name = 'x')\n",
        "y = tf1.placeholder(tf1.float32, shape = (None,1), name = 'y')\n",
        "\n",
        "with tf1.name_scope('loss'):\n",
        "    #theta = tf.Variable(tf.random_uniform((8,1), -1.0, 1.0), name = 'theta')\n",
        "    stddev = 2/np.sqrt(8)\n",
        "    w = tf1.Variable(tf1.random_normal((8,1), stddev = stddev, name = 'weights'))\n",
        "    b = tf1.Variable(tf1.zeros(m,1), name = 'biases')\n",
        "    y_pred = tf1.add(tf1.matmul(X,w),b, name= 'predictions')\n",
        "    error = y_pred - y\n",
        "    mse = tf1.reduce_mean(tf1.square(error), name = 'mse')\n",
        "    \n",
        "with tf1.name_scope('training'):\n",
        "    learning_rate = 0.01\n",
        "    optimizer= tf1.train.RMSPropOptimizer(learning_rate = learning_rate)\n",
        "    training_op = optimizer.minimize(mse)\n",
        "    init = tf1.global_variables_initializer()\n",
        "    saver = tf1.train.Saver()\n",
        "    \n",
        "train_loss, test_loss = [],[]\n",
        "\n",
        "n_epochs = 50\n",
        "with tf1.Session() as sess:\n",
        "    \n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        batch_step = 0\n",
        "        avg_loss = 0\n",
        "        total_loss = 0\n",
        "        total_batch = int(X_train.shape[0]/batch_size)\n",
        "        for batch_index in range(n_batches):\n",
        "            x_batch, y_batch = fetch_batch(batch_index)\n",
        "            _,l = sess.run([training_op, mse], feed_dict= {X:x_batch, y:y_batch})\n",
        "            batch_step+=1\n",
        "            total_loss +=l\n",
        "        if epoch % 10 == 0: # print 5 batches of epochs\n",
        "            avg_loss = total_loss/batch_size\n",
        "            print(\"Epoch:\", '%02d' % (epoch+1), \"| Average Training Loss= {:.2f}\".format(avg_loss), \n",
        "                  \"| Training MSE:  {:.2f}\".format(mse.eval({X: X_train, y: y_train})),\n",
        "                  \"| Test/Validation MSE:  {:.2f}\".format(mse.eval({X: X_test, y: y_test})))\n",
        "            train_loss.append(mse.eval({X:X_train, y:y_train}))\n",
        "            test_loss.append(mse.eval({X:X_test, y:y_test}))\n",
        "        else:\n",
        "            train_loss.append(mse.eval({X:X_train, y:y_train}))\n",
        "            test_loss.append(mse.eval({X:X_test, y:y_test}))\n",
        "    \n",
        "    print(\"Model fit complete.\")\n",
        "    print(\"Final Training MSE: {:.2f}\".format(mse.eval({X: X_train, y: y_train})))\n",
        "    print(\"Final Validation MSE: {:.2f}\".format(mse.eval({X: X_test, y: y_test})))\n",
        "    save_path = saver.save(sess, './house_reg.ckpt')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Average Training Loss= 300.59 | Training MSE:  4847.35 | Test/Validation MSE:  4729.87\n",
            "Epoch: 11 | Average Training Loss= 1.73 | Training MSE:  46.83 | Test/Validation MSE:  46.04\n",
            "Epoch: 21 | Average Training Loss= 1.55 | Training MSE:  52.17 | Test/Validation MSE:  51.52\n",
            "Epoch: 31 | Average Training Loss= 1.51 | Training MSE:  54.52 | Test/Validation MSE:  53.77\n",
            "Epoch: 41 | Average Training Loss= 1.53 | Training MSE:  49.69 | Test/Validation MSE:  48.99\n",
            "Model fit complete.\n",
            "Final Training MSE: 31.41\n",
            "Final Validation MSE: 30.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGfZ4j82q6y1"
      },
      "source": [
        "# test_loss"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "Z6QcFmaXa2FS",
        "outputId": "e18b83f7-26d6-49e6-aadc-4faf1bcb3591"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss)\n",
        "plt.plot(test_loss)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRY_fdo0a2FS"
      },
      "source": [
        "## Keras in Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cblZwMM2a2FS"
      },
      "source": [
        "import keras \n",
        "from tensorflow.compat.v1.keras.backend import clear_session\n",
        "# Before instantiating a tf.data.Dataset obj & before model creation, call:\n",
        "clear_session()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF49broAa2FS"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "import datetime\n",
        "logdir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "model = tf1.keras.Sequential()\n",
        "model.add(layers.Dense(40,input_shape=(8,), activation='relu'))\n",
        "model.add(layers.Dense(100, activation='relu'))\n",
        "model.add(layers.Dense(20, activation='relu'))\n",
        "model.add(layers.Dense(1))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuJSWfKga2FS",
        "outputId": "67d81218-2b1f-4bb7-a5c2-7a1b88a75546"
      },
      "source": [
        "model.compile(optimizer=tf1.keras.optimizers.RMSprop(0.01),\n",
        "              loss= tf1.keras.losses.mean_squared_error,\n",
        "              metrics=['mse'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 40)                360       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               4100      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                2020      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 6,501\n",
            "Trainable params: 6,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7UHgEGZa2FT",
        "outputId": "8f97a19e-a3aa-4a18-9eba-ac845b547953"
      },
      "source": [
        "h = model.fit(X_train, y_train, epochs=50, batch_size=1000,validation_data=(X_test, y_test),callbacks=[tensorboard_callback])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 16512 samples, validate on 4128 samples\n",
            "Epoch 1/50\n",
            "16512/16512 [==============================] - 0s 7us/sample - loss: 57441.3579 - mse: 57441.3594 - val_loss: 2.5870 - val_mse: 2.5870\n",
            "Epoch 2/50\n",
            "16512/16512 [==============================] - 0s 4us/sample - loss: 2.3349 - mse: 2.3349 - val_loss: 2.1552 - val_mse: 2.1552\n",
            "Epoch 3/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 2.2100 - mse: 2.2100 - val_loss: 1.8987 - val_mse: 1.8987\n",
            "Epoch 4/50\n",
            "16512/16512 [==============================] - 0s 4us/sample - loss: 2.4825 - mse: 2.4825 - val_loss: 2.9490 - val_mse: 2.9490\n",
            "Epoch 5/50\n",
            "16512/16512 [==============================] - 0s 4us/sample - loss: 2.8969 - mse: 2.8969 - val_loss: 3.0775 - val_mse: 3.0775\n",
            "Epoch 6/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 3.7831 - mse: 3.7831 - val_loss: 1.9305 - val_mse: 1.9305\n",
            "Epoch 7/50\n",
            "16512/16512 [==============================] - 0s 4us/sample - loss: 4.5707 - mse: 4.5707 - val_loss: 4.3021 - val_mse: 4.3021\n",
            "Epoch 8/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1315.3562 - mse: 1315.3561 - val_loss: 4.7183 - val_mse: 4.7183\n",
            "Epoch 9/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 4.7741 - mse: 4.7741 - val_loss: 4.6273 - val_mse: 4.6273\n",
            "Epoch 10/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 4.6382 - mse: 4.6382 - val_loss: 4.4284 - val_mse: 4.4284\n",
            "Epoch 11/50\n",
            "16512/16512 [==============================] - 0s 4us/sample - loss: 4.3636 - mse: 4.3636 - val_loss: 4.0701 - val_mse: 4.0701\n",
            "Epoch 12/50\n",
            "16512/16512 [==============================] - 0s 4us/sample - loss: 3.9468 - mse: 3.9468 - val_loss: 3.6151 - val_mse: 3.6151\n",
            "Epoch 13/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 3.4820 - mse: 3.4820 - val_loss: 3.1641 - val_mse: 3.1641\n",
            "Epoch 14/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 3.0452 - mse: 3.0452 - val_loss: 2.7582 - val_mse: 2.7582\n",
            "Epoch 15/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 2.6569 - mse: 2.6569 - val_loss: 2.4036 - val_mse: 2.4036\n",
            "Epoch 16/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 2.3212 - mse: 2.3212 - val_loss: 2.1022 - val_mse: 2.1022\n",
            "Epoch 17/50\n",
            "16512/16512 [==============================] - 0s 4us/sample - loss: 2.0380 - mse: 2.0380 - val_loss: 1.8529 - val_mse: 1.8529\n",
            "Epoch 18/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.8062 - mse: 1.8062 - val_loss: 1.6529 - val_mse: 1.6529\n",
            "Epoch 19/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.6241 - mse: 1.6241 - val_loss: 1.5021 - val_mse: 1.5021\n",
            "Epoch 20/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.4908 - mse: 1.4908 - val_loss: 1.3997 - val_mse: 1.3997\n",
            "Epoch 21/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.4033 - mse: 1.4033 - val_loss: 1.3386 - val_mse: 1.3386\n",
            "Epoch 22/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3561 - mse: 1.3561 - val_loss: 1.3147 - val_mse: 1.3147\n",
            "Epoch 23/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3393 - mse: 1.3393 - val_loss: 1.3104 - val_mse: 1.3104\n",
            "Epoch 24/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3369 - mse: 1.3369 - val_loss: 1.3109 - val_mse: 1.3109\n",
            "Epoch 25/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3370 - mse: 1.3370 - val_loss: 1.3107 - val_mse: 1.3107\n",
            "Epoch 26/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3371 - mse: 1.3371 - val_loss: 1.3105 - val_mse: 1.3105\n",
            "Epoch 27/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3370 - mse: 1.3370 - val_loss: 1.3106 - val_mse: 1.3106\n",
            "Epoch 28/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3370 - mse: 1.3370 - val_loss: 1.3115 - val_mse: 1.3115\n",
            "Epoch 29/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3370 - mse: 1.3370 - val_loss: 1.3104 - val_mse: 1.3104\n",
            "Epoch 30/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3370 - mse: 1.3370 - val_loss: 1.3106 - val_mse: 1.3106\n",
            "Epoch 31/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3369 - mse: 1.3369 - val_loss: 1.3107 - val_mse: 1.3107\n",
            "Epoch 32/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3371 - mse: 1.3371 - val_loss: 1.3109 - val_mse: 1.3109\n",
            "Epoch 33/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3371 - mse: 1.3371 - val_loss: 1.3105 - val_mse: 1.3105\n",
            "Epoch 34/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3370 - mse: 1.3370 - val_loss: 1.3122 - val_mse: 1.3122\n",
            "Epoch 35/50\n",
            "16512/16512 [==============================] - 0s 4us/sample - loss: 1.3371 - mse: 1.3371 - val_loss: 1.3108 - val_mse: 1.3108\n",
            "Epoch 36/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3371 - mse: 1.3371 - val_loss: 1.3105 - val_mse: 1.3105\n",
            "Epoch 37/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3371 - mse: 1.3371 - val_loss: 1.3105 - val_mse: 1.3105\n",
            "Epoch 38/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3370 - mse: 1.3370 - val_loss: 1.3105 - val_mse: 1.3105\n",
            "Epoch 39/50\n",
            "16512/16512 [==============================] - 0s 4us/sample - loss: 1.3372 - mse: 1.3372 - val_loss: 1.3106 - val_mse: 1.3106\n",
            "Epoch 40/50\n",
            "16512/16512 [==============================] - 0s 4us/sample - loss: 1.3371 - mse: 1.3371 - val_loss: 1.3104 - val_mse: 1.3104\n",
            "Epoch 41/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3372 - mse: 1.3372 - val_loss: 1.3107 - val_mse: 1.3107\n",
            "Epoch 42/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3370 - mse: 1.3370 - val_loss: 1.3109 - val_mse: 1.3109\n",
            "Epoch 43/50\n",
            "16512/16512 [==============================] - 0s 4us/sample - loss: 1.3371 - mse: 1.3371 - val_loss: 1.3110 - val_mse: 1.3110\n",
            "Epoch 44/50\n",
            "16512/16512 [==============================] - 0s 4us/sample - loss: 1.3370 - mse: 1.3370 - val_loss: 1.3107 - val_mse: 1.3107\n",
            "Epoch 45/50\n",
            "16512/16512 [==============================] - 0s 4us/sample - loss: 1.3371 - mse: 1.3371 - val_loss: 1.3105 - val_mse: 1.3105\n",
            "Epoch 46/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3370 - mse: 1.3370 - val_loss: 1.3104 - val_mse: 1.3104\n",
            "Epoch 47/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3371 - mse: 1.3371 - val_loss: 1.3112 - val_mse: 1.3112\n",
            "Epoch 48/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3369 - mse: 1.3369 - val_loss: 1.3105 - val_mse: 1.3105\n",
            "Epoch 49/50\n",
            "16512/16512 [==============================] - 0s 5us/sample - loss: 1.3369 - mse: 1.3369 - val_loss: 1.3115 - val_mse: 1.3115\n",
            "Epoch 50/50\n",
            "16512/16512 [==============================] - 0s 4us/sample - loss: 1.3373 - mse: 1.3373 - val_loss: 1.3108 - val_mse: 1.3108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st8LBg4sk3vh"
      },
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir logs/scalars"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZh4EPGrdnwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a91bb90-15ca-4a99-db38-a1bd205f2f82"
      },
      "source": [
        "model.evaluate(X_train, y_train)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3367909963509834, 1.3367921]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnDeIz60r_Az",
        "outputId": "96223f62-4c4e-4123-d96f-d922558b0e78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3108301001001699, 1.3108299]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs0KdBc1sJpd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}